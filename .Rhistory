# Print the result
print(conf_interval)
model
summary(model)
# Change the baseline category for the rank variable to "Assistant Professor"
salary$rank <- relevel(salary$rank, ref = "Asst")
# Run multiple linear regression
model_with_new_baseline <- lm(salary ~ degree + rank + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_with_new_baseline)
# Change the baseline category for the rank variable to "Assistant Professor"
salary$rank <- relevel(salary$rank, ref = "Assoc")
# Run multiple linear regression
model_with_new_baseline <- lm(salary ~ degree + rank + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_with_new_baseline)
# Change the baseline category for the rank variable to "Assistant Professor"
salary$rank <- relevel(salary$rank, ref = "Asst")
# Run multiple linear regression
model_with_new_baseline <- lm(salary ~ degree + rank + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_with_new_baseline)
#excluding "rank"
model_without_rank <- lm(salary ~ degree + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_without_rank)
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$YearHighestDegree - salary$NewDeanYear) <= 15, 1, 0)
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg - salary$NewDeanYear) <= 15, 1, 0)
summary(salary)
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg) <= 15, 1, 0)
# Run multiple regression
salary_model <- lm(salary ~ NewDeanHire + degree + sex + year + ysdeg, data = salary)
# Check for multicollinearity
cor_matrix <- cor(salary[, c("salary", "NewDeanHire", "degree", "sex", "year", "ysdeg")])
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg) <= 15, 1, 0)
# Run multiple regression
salary_model <- lm(salary ~ NewDeanHire + degree + sex + year + ysdeg, data = salary)
# Check for multicollinearity
cor_matrix <- cor(salary[, c("NewDeanHire", "degree", "sex", "year", "ysdeg")])
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg) <= 15, 1, 0)
# Check correlation between 'new_dean' and 'ysdeg'
correlation_result <- cor.test(salary$new_dean, salary$ysdeg)
salary$new_dean <- ifelse(salary$ysdeg <= 15, 1, 0)
cor.test(salary$new_dean, salary$ysdeg)
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg) <= 15, 1, 0)
# Check correlation between 'new_dean' and 'ysdeg'
correlation_result <- cor.test(salary$NewDeanHire, salary$ysdeg)
print(correlation_result)
model_excluding_ysdeg <- lm(salary ~ . - ysdeg, data = salary)
model_including_ysdeg <- lm(salary ~ ., data = salary)
model_excluding_ysdeg <- lm(salary ~ . - ysdeg, data = salary)
model_including_ysdeg <- lm(salary ~ ., data = salary)
# Summary for model excluding 'ysdeg'
summary(model_excluding_ysdeg)
# Summary for model including 'ysdeg'
summary(model_including_ysdeg)
#load data
data(salary)
data("house.selling.price")
library(tidyverse)
library(alr4)
library(smss)
library(ggplot2)
library(stargazer)
library(RColorBrewer)
#load data
data(salary)
data("house.selling.price")
# Given values
x1 <- 1240
x2 <- 18000
intercept <- -10536
coef_x1 <- 53.8
coef_x2 <- 2.84
actual_selling_price <- 145000
# Calculate predicted selling price
predicted_selling_price <- intercept + coef_x1 * x1 + coef_x2 * x2
# Calculate residual
residual <- actual_selling_price - predicted_selling_price
# Print the results
cat("Predicted Selling Price:", predicted_selling_price, "\n")
cat("Residual:", residual, "\n")
equivalent_lot_size_increase <- coef_x1 / coef_x2
# Print the result
cat("Equivalent increase in lot size:", equivalent_lot_size_increase, "square feet\n")
#salaries for men and women
salary_men <- salary$salary[salary$sex == "Male"]
salary_women <- salary$salary[salary$sex == "Female"]
# Perform a two-sample t-test
t_test_result <- t.test(salary_men, salary_women)
# Print the result
print(t_test_result)
# Run multiple linear regression
model <- lm(salary ~ degree + rank + sex + year + ysdeg, data = salary)
# Obtain 95% confidence interval for the difference in salary between males and females
conf_interval <- confint(model, "sexFemale", level = 0.95)
# Print the result
print(conf_interval)
summary(model)
# Change the baseline category for the rank variable to "Assistant Professor"
salary$rank <- relevel(salary$rank, ref = "Asst")
# Run multiple linear regression
model_with_new_baseline <- lm(salary ~ degree + rank + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_with_new_baseline)
#excluding "rank"
model_without_rank <- lm(salary ~ degree + sex + year + ysdeg, data = salary)
# Display coefficients
summary(model_without_rank)
# Create the binary variable
salary$NewDeanHire <- ifelse((salary$ysdeg) <= 15, 1, 0)
# Check correlation between 'new_dean' and 'ysdeg'
correlation_result <- cor.test(salary$NewDeanHire, salary$ysdeg)
print(correlation_result)
model_excluding_ysdeg <- lm(salary ~ . - ysdeg, data = salary)
model_including_ysdeg <- lm(salary ~ ., data = salary)
# Summary for model excluding 'ysdeg'
summary(model_excluding_ysdeg)
# Summary for model including 'ysdeg'
summary(model_including_ysdeg)
# Run the regression model
selling_price_model <- lm(selling_price ~ size_of_home + is_new, data = house.selling.price)
# Run the regression model
selling_price_model <- lm(Price ~ Size + New, data = house.selling.price)
# Print the summary of the regression results
summary(selling_price_model)
# Coefficients from the regression
intercept <- -40230.867
coef_size <- 116.132
coef_new <- 57736.283
# Size of the home
size <- 3000
# Predicted selling price for a new home
predicted_price_new <- intercept + coef_size * size + coef_new * 1
# Predicted selling price for a not new home
predicted_price_not_new <- intercept + coef_size * size + coef_new * 0
# Display the results
cat("Predicted selling price for a new home:", predicted_price_new, "\n")
cat("Predicted selling price for a not new home:", predicted_price_not_new, "\n")
# Create a data frame with the predictor variables
new_data <- data.frame(Size = 3000, New = c(1, 0))
# Predict the selling prices using the model
predicted_prices <- predict(selling_price_model, newdata = new_data)
# Display the results
cat("Predicted selling price for a new home:", predicted_prices[1], "\n")
cat("Predicted selling price for a not new home:", predicted_prices[2], "\n")
fit_interaction <- lm(Price ~ Size * New, data = house.selling.price)
# Display regression results
summary(fit_interaction)
# Predicting the selling prices
predicted_prices <- predict(fit_interaction, newdata = new_data)
# Displaying the predicted prices
predicted_prices
# Creating a data frame with the specific values
new_data_1500 <- data.frame(Size = 1500, New = c(1, 0))
# Predicting the selling prices
predicted_prices_1500 <- predict(fit_interaction, newdata = new_data_1500)
# Displaying the predicted prices
predicted_prices_1500
# Calculating the differences
price_difference <- predicted_prices - predicted_prices_1500
# Displaying the differences
price_difference
# Creating a data frame with the specific values
new_data_1500 <- data.frame(Size = 1500, New = c(1, 0))
# Predicting the selling prices
predicted_prices_1500 <- predict(fit_interaction, newdata = new_data_1500)
# Displaying the predicted prices for 1500 sq ft and 3000 sq ft
predicted_prices
predicted_prices_1500
# Calculating the differences
price_difference <- predicted_prices - predicted_prices_1500
# Displaying the differences
price_difference
# Creating a data frame with the specific values
new_data_1500 <- data.frame(Size = 1500, New = c(1, 0))
# Predicting the selling prices
predicted_prices_1500 <- predict(fit_interaction, newdata = new_data_1500)
# Displaying the predicted prices for 1500 sq ft and 3000 sq ft
predicted_prices
predicted_prices_1500
# Calculating the differences
price_difference <- predicted_prices - predicted_prices_1500
# Displaying the differences
price_difference
# Displaying the differences
price_difference
# Calculating the differences
price_difference <- predicted_prices - predicted_prices_1500
# Calculating the differences
price_difference <- predicted_prices - predicted_prices_1500
# Displaying the differences
price_difference
#load data
data("house.selling.price.2")
library(tidyverse)
library(alr4)
library(smss)
library(ggplot2)
library(stargazer)
library(RColorBrewer)
#load data
data("house.selling.price.2")
#fit all
model_all <- lm(Price ~ ., data = house)
View(house.selling.price.2)
#fit all
model_all <- lm(Price ~ ., data = house.selling.price.2)
#fit all
model_all <- lm(P ~ ., data = house.selling.price.2)
# Fit the model without Beds
model_no_beds <- lm(P ~ . - Be, data = house)
#fit all
model_all <- lm(P ~ ., data = house.selling.price.2)
# Fit the model without Beds
model_no_beds <- lm(P ~ . - Be, data = house.selling.price.2)
# Extracting metrics for the all model
rsq_all <- summary(model_all)$r.squared
adj_rsq_all <- summary(model_all)$adj.r.squared
PRESS_all <- sum((residuals(model_all) / (1 - lm.influence(model_all)$hat))^2)
AIC_all <- AIC(model_all)
BIC_all <- BIC(model_all)
# Extracting metrics for the model without Beds
rsq_nobeds <- summary(model_no_beds)$r.squared
adj_rsq_nobeds <- summary(model_no_beds)$adj.r.squared
PRESS_nobeds <- sum((residuals(model_no_beds) / (1 - lm.influence(model_no_beds)$hat))^2)
AIC_nobeds <- AIC(model_no_beds)
BIC_nobeds <- BIC(model_no_beds)
# Create a data frame to display the results
result_df <- data.frame(
models = c('model_all', 'model_no_beds'),
rsq = c(rsq_all, rsq_nobeds),
adj.rsq = c(adj_rsq_all, adj_rsq_nobeds),
PRESS = c(PRESS_all, PRESS_nobeds),
AIC = c(AIC_all, AIC_nobeds),
BIC = c(BIC_all, BIC_nobeds)
)
# Print the results
print(result_df)
View(result_df)
results_df
result_df
#load data
data("house.selling.price.2")
data(trees)
# Fit a multiple regression model
model_volume <- lm(Volume ~ Girth + Height, data = trees)
# Display the summary of the model
summary(model_volume)
# Run regression diagnostic plots
par(mfrow = c(2, 2))
plot(model_volume)
# Run regression diagnostic plots
par(mfrow = c(2, 2))
plot(model_volume)
# Reset the plotting layout
par(mfrow = c(1, 1))
View(model_volume)
# Run regression diagnostic plots
par(mfrow = c(2, 3))
plot(model_volume, which = 1:6)
# Reset the plotting layout
par(mfrow = c(1, 1))
# Fit a model with a quadratic term
model_quadratic <- lm(Volume ~ Girth + Height + I(Girth^2), data = trees)
summary(model_quadratic)
plot(model_quadratic, which = 1)
model_election <- lm(Buchanan ~ Bush, data = your_data)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 1:6)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 1:4)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 2))
plot(model_election)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 2))
plot(model_election)
# Reset the plotting layout
par(mfrow = c(1, 1))
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 6)
# Reset the plotting layout
par(mfrow = c(1, 1))
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 1:6)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 6)
model_election <- lm(Buchanan ~ Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election, which = 1:6)
# Take the log of both variables
florida$log_Bush <- log(florida$Bush)
florida$log_Buchanan <- log(florida$Buchanan)
# Run the regression model with log-transformed variables
model_election_log <- lm(log_Buchanan ~ log_Bush, data = florida)
# Plot diagnostic plots
par(mfrow = c(2, 3))
plot(model_election_log, which = 1:6)
setwd("~/Graduate School/DACSS 690R/SpotifyDataCleaning")
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Load necessary libraries
library(readr)
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Step 1: Remove duplicates
spotify_data <- spotify_data[!duplicated(spotify_data), ]
# Step 2: Handle missing values (example: fill with median if missing)
spotify_data$streams[is.na(spotify_data$streams)]
# Step 2: Handle missing values (example: fill with median if missing)
spotify_data$streams[is.na(spotify_data$streams)]
# Step 2: Handle missing values (example: fill with median if missing)
spotify_data$streams[is.na(spotify_data$streams)] <- median(spotify_data$streams, na.rm = TRUE)
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Step 1: Remove duplicates
spotify_data <- spotify_data[!duplicated(spotify_data), ]
# Step 1: Identify missing values
missing_values <- sapply(spotify_data, function(x) sum(is.na(x)))
print(missing_values)
# View columns with missing data
missing_data_columns <- spotify_data[, colSums(is.na(spotify_data)) > 0]
head(missing_data_columns)
View(spotify_data)
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Step 1: Remove duplicates
spotify_data <- spotify_data[!duplicated(spotify_data), ]
# Step 3: Combine date columns into one
spotify_data$release_date <- as.Date(with(spotify_data, paste(released_year, released_month, released_day, sep = "-")), "%Y-%m-%d")
View(spotify_data)
colnames(spotify_data)
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(artist_count,in_apple_playlists,in_apple_charts,in_deezer_playlists,in_deezer_charts,in_shzam_charts)
View(spotify_data)
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(artist_count,in_apple_playlists,in_apple_charts,in_deezer_playlists,in_deezer_charts,in_shzam_charts)
View(spotify_data)
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts
))
View(spotify_data)
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts,
released_year,
relaesed_month,
realeased_day
))
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Step 3: Combine date columns into one
spotify_data$release_date <- as.Date(with(spotify_data, paste(released_year, released_month, released_day, sep = "-")), "%Y-%m-%d")
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts,
released_year,
relaesed_month,
realeased_day
))
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts,
released_year,
released_month,
realeased_day
))
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts,
released_year,
released_month,
released_day
))
# Save cleaned Spotify data
write_csv(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.csv")
saveRDS(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.RDS")
# Check for duplicates
duplicates <- spotify_data[duplicated(spotify_data), ]
# Print the number of duplicate rows
cat("Number of duplicate rows:", nrow(duplicates), "\n")
# View the actual duplicate rows, if any
head(duplicates)
# Combine date columns into one
spotify_data$release_date <- as.Date(with(spotify_data, paste(released_year, released_month, released_day, sep = "-")), "%Y-%m-%d")
# Load necessary libraries
library(readr)
# Load the dataset
spotify_data <- read_csv("Spotify Most Streamed Songs.csv")
# Check for duplicates
duplicates <- spotify_data[duplicated(spotify_data), ]
# Print the number of duplicate rows
cat("Number of duplicate rows:", nrow(duplicates), "\n")
# View the actual duplicate rows, if any
head(duplicates)
# Combine date columns into one
spotify_data$release_date <- as.Date(with(spotify_data, paste(released_year, released_month, released_day, sep = "-")), "%Y-%m-%d")
# Drop unwanted columns
spotify_data <- subset(spotify_data, select = -c(
artist_count,
in_apple_playlists,
in_apple_charts,
in_deezer_playlists,
in_deezer_charts,
in_shazam_charts,
released_year,
released_month,
released_day
))
# Save cleaned Spotify data
write_csv(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.csv")
saveRDS(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.RDS")
missing_values <- sapply(spotify_data, function(x) sum(is.na(x)))
print(missing_values)
#Identify missing values
missing_values <- sapply(spotify_data, function(x) sum(is.na(x)))
print(missing_values)
#Replace missing values in the 'key' column with "Unknown"
spotify_data$key[is.na(spotify_data$key)] <- "Unknown"
# Save cleaned Spotify data
write_csv(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.csv")
saveRDS(spotify_data, "DataCleanAndFormatted/Spotify_Cleaned.RDS")
View(spotify_data)
colnames(spotify_data)
# Load the dataset
hot100_data <- read_csv("hot100.csv")
colnames(hot100_data)
head(hot100_data)
View(hot100_data)
library(dplyr)
# Load the Hot100 dataset
hot100_data <- read_csv("hot100.csv")
# Convert the 'Date' column to a Date format
hot100_data$Date <- as.Date(hot100_data$Date, format = "%m/%d/%Y")
View(hot100_data)
# Filter the dataset to only include dates from 2023
hot100_data_2023 <- hot100_data %>%
filter(format(Date, "%Y") == "2023")
# Check the result
head(hot100_data_2023)
View(hot100_data_2023)
# Save the filtered data for later use
write_csv(hot100_data_2023, "DataCleanAndFormatted/Hot100_2023.csv")
saveRDS(hot100_data_2023, "DataCleanAndFormatted/Hot100_2023.RDS")
# Check for duplicates in the Hot 100 data
duplicates_hot100 <- hot100_data_2023[duplicated(hot100_data_2023), ]
# Print the number of duplicate rows
cat("Number of duplicate rows:", nrow(duplicates_hot100), "\n")
# View the actual duplicate rows, if any
head(duplicates_hot100)
#femove unneeded columns
hot100_data_2023 <- subset(hot100_data_2023, select = -c(`Image URL`, `Last Week`))
View(hot100_data)
View(hot100_data_2023)
# Check for missing values in the Hot 100 data
missing_values_hot100 <- sapply(hot100_data_2023, function(x) sum(is.na(x)))
print(missing_values_hot100)
library(lubridate)
# Add a 'Week' column based on the week of the year from the 'Date' column
hot100_data_2023$Week <- isoweek(hot100_data_2023$Date)
# Check the result
head(hot100_data_2023)
View(hot100_data_2023)
# Save the filtered data for later use
write_csv(hot100_data_2023, "DataCleanAndFormatted/Hot100_2023.csv")
saveRDS(hot100_data_2023, "DataCleanAndFormatted/Hot100_2023.RDS")
